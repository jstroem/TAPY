\chapter{Analysing Functions}
\label{Functions}
In this chapter we motivate why the analyser puts two objects on the abstract heap for each function declaration, as mentioned in \autoref{The Stack}. One being the function object, and the other being the function scope object. The function object is necessary as functions are themselves objects, just like in JavaScript. For instance we can set an attribute on a function object:

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def foo(): pass
foo.attr = 42
	\end{minted}
\caption{Setting an attribute on a function object.}
\label{code:FunctionPropertyExample}
\end{listing}

%Another thing with regards to function objects on the heap, is that Python has a built in method \inlinecode{\_\_call\_\_} on each function. This method is a function wrapper of the function itself; calling it will result in calling the function itself. We therefore map the attribute \inlinecode{\_\_call\_\_} on the function object to its function wrapper object. The following illustrates how each newly declared function has this method:

%\begin{listing}[H]
%	\begin{minted}[linenos]{python}
%def a():
%	print "a"
%a() // "a"
%a.__call__ # <method-wrapper '__call__' of function object at ...> 
%a.__call__() # "a"
%	\end{minted}
%\caption{On a newly declared function the \_\_call\_\_ attribute is set to a built in method wrapper.}\label{code:printFunctionExample}
%\end{listing}

%It is important to distinguish between the object of the function, and the function object, since \inlinecode{\_\_call\_\_} is not just a reference to the object of the function, as illustrated below:

%\begin{listing}[H]
%	\begin{minted}[linenos]{python}
%def a(): 
%	pass
%
%# TypeError: 'method-wrapper' object has only read-only attributes
%a.__call__.prop = 10
%	\end{minted}
%\caption{Function object and \_\_call\_\_ example}
%\label{code:callPropertyExample}
%\end{listing}

The function scope object is necessary as local variables inside a function should not be set as attributes on the function object (see \autoref{code:callPropertyExample}). In the analysis only one function scope object is created on the abstract heap. This is an abstraction since at runtime a new function scope object is created for each invocation of a particular function. This abstraction makes it possible to create the function scope object in our analysis when the function is declared.

A better abstraction would be to create a new function scope object for each call site. This is in fact what TAJS \cite{tajs} does. However, this abstraction has the same precision issues when faced with recursive functions.

No matter which abstraction is used, there is a potential for the precision of the analysis to be ruined, because all local variable writes must be modelled as weak updates to preserve soundness. This is discussed in \autoref{section:Strong or weak} about strong and weak updates.

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def foo(): 
  x = 42
foo.x # AttributeError
	\end{minted}
\caption{Function object and \_\_call\_\_ example}
\label{code:callPropertyExample}
\end{listing}


\section{Calling functions and updating the call graph}
A function call is represented by a \textit{CallNode} and an \textit{AfterCallNode} in the CFG.

If the register being called points to a function $f(p_1, ..., p_n)$, the function scope object of $f$ is found on the abstract heap, which is needed to handle parameter passing. For each parameter $p_i$ of $f$ we set $p_i$ as an attribute on the scope object of $f$ to the abstract value of the $i$'th supplied argument. This implies that reading the variable $p_i$ inside the function will yield the $i$'th supplied argument. 

In Python default arguments are supported. This is handled in the analysis by evaluating the default arguments in the CFG whenever a function is declared. The abstract values of the default arguments are saved in a list of registers which is used as standin for absent arguments when the particular function is called.

If the function is called more than once with different parameters, reading the $i$'th argument inside the function will result in the least upper bound of all $i$'th supplied arguments because we have no context sensitivity\footnote{In \cite{sa} it is described how the call string and functional approach can be used to obtain context sensivity.}. The following example illustrates this:

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def f(p1): 
  return p1
f(10)
x = f(20) # x becomes the top element of the integer lattice, not 20
	\end{minted}
\caption{A consequence of not having context sensitivity.}
\end{listing}

Next, we update the call graph by inserting call edges from the call node to the entry node of $f$ and from the exit node of $f$ to the after call node. This implies that the worklist of our fixed-point algorithm will be updated with the entry node of $f$, such that it will be reevaluated.

At the function entry node we change the dynamic scope chain to the static scope chain of the function as mentioned in \autoref{The Stack}, which is found in the function object on the abstract heap.

When the fixed-point algorithm has processed a function the after call node can read the return value of the function and store it on the stack. The return value is stored in a special fixed register. Whenever the analysis encounters a return node it writes the returned value to this special register using a weak update.

We discuss how two take care of interprocedural exception flow in \autoref{chapter:Exceptions}.

\section{Strong or weak updates of local variables}
\label{section:Strong or weak}
Since only one scope object is created for each function there is a big potential for precision loss because soundness dictates that all writes to local variables are modelled as weak updates, i.e. least upper bound between the current value and the new value. This is due to the fact that a scope object of a particular function might exist in more than one instance at runtime, as it is the case with recursive functions.

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def foo(i):
  if i==10:
    return
  else:
    foo(i+5)
foo(0)
	\end{minted}
\caption{Simple recursive function.}
\label{code:UnfoldDictFunctionExample}
\end{listing}

In \autoref{code:UnfoldDictFunctionExample} three function scope objects would exist simultaneously for \inlinecode{foo} at runtime. However, our abstraction only has one object so it needs to model all values of $i$ in the same summary. The only way to do this is to take the least upper bound of these abstract values resulting in the top element of the $Integer$ lattice.

The problem only arises in the presence of recursive functions, so to enable the analysis to do strong updates a command-line flag is introduced to tell the analysis if it can assume no recursive functions occur. This was very fast to implement and allowed more time to focus on the magic methods, which on their own doesn't introduce any recursion.

Alternatively, the call graph could be inspected for loops in order to detect recursive functions. However since the call graph is built dynamically as a part of the analysis a recursive function might not appear as recursive at the current iteration possibly leading to strong updates, thus special care is needed when functions are labeled recursive.

An entirely different approach is to use the recency abstraction as introduced by \cite{recency}, which can be seen as an extension of the allocation-site abstraction. The idea is to allocate two objects for each allocation-site $s$, namely the most-recently-allocated-block (MRAB[$s$]) and not-most-recently-allocated-blocks (NMRAB$s$), instead of only one as in the allocation-site abstraction. This will allow for strong updates to attributes of MRAB[$s$]. This turns out to work very well because all writes to local variables at runtime happen to the latest instantiated stack frame, which is exactly the situation in which recency abstraction enables strong updates over weak updates.


\section{Further work with parameter passing}
In Python it is possible to unfold e.g. a dictionary to the arguments of a function:

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def foo(bar, baz):
	return bar + baz
params = { 'bar': 'bar', 'baz': 'baz' }
foo(*params) # 'barbaz'
	\end{minted}
\caption{Unfolding of a dictionary to the parameters a function.}\label{code:UnfoldDictFunctionExample}
\end{listing}

Currently, our analysis does not support this kind of parameter passing. Also, it does not support the special \inlinecode{**args} parameter that collects all of the superfluous arguments in a list, quite similar to the \inlinecode{arguments} object that is available inside functions in JavaScript.