\chapter{Handling functions}
\label{Functions}
In this chapter we start with motivating why it is necessary to have three objects on the heap for each function declaration. Consider the below example \ref{code:FunctionPropertyExample}. As mentioned we create a function object on the heap for each function declaration. This object is necessary as functions are themselves objects, just like in e.g. JavaScript. For instance we can set a property on a function object as line 2 illustrates.

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def a(): pass
a.prop = 42
	\end{minted}
\caption{Property on function object}\label{code:FunctionPropertyExample}
\end{listing}

Thus for this concrete example we map the property \inlinecode{prop} to the integer 42 on the object of the function.

Another relevant thing with regards to function objects on the heap, is that Python has a built in method \inlinecode{\_\_call\_\_} on each function. This method is a function wrapper of the function itself; calling it will result in calling the function itself. We therefore map the property \inlinecode{\_\_call\_\_} on the function object to its function wrapper object. The following illustrates how each newly declared function has this method:

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def a():
	print "a"
a() // "a"
a.__call__ # <method-wrapper '__call__' of function object at ...> 
a.__call__() # "a"
	\end{minted}
\caption{On a newly declared function the \_\_call\_\_ property is set to a built in method wrapper.}\label{code:printFunctionExample}
\end{listing}

It is important to distinguish between the object of the function, and the function object, since \inlinecode{\_\_call\_\_} is not just a reference to the object of the function, as illustrated below:

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def a(): 
	pass

# TypeError: 'method-wrapper' object has only read-only attributes
a.__call__.prop = 10
	\end{minted}
\caption{Function object and \_\_call\_\_ example}\label{code:callPropertyExample}
\end{listing}

Finally, the scope object of a function in example \ref{code:callPropertyExample} is necessary as local variables inside a function should not be set as properties on the object of the function:

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def a(): 
	x = 42
a.x # AttributeError
	\end{minted}
\caption{Function object and \_\_call\_\_ example}\label{code:callPropertyExample}
\end{listing}


\section{Calling functions and updating the call graph}
A call is represented by a \inlinecode{CallNode} (and \inlinecode{AfterCallNode}) in the CFG.

If the value being called is a function $f(p_1, ..., p_2)$, we first look up the scope object of the function $f$ on the heap. We need the scope object of the function in order to handle parameter passing: For each parameter $p_i$ of $f$ we set $p_i$ as an attribute on the scope object of $f$ to the value of $a_i$, the i'th supplied argument. This implies that reading the variable $a_i$ inside the function will yield the supplied argument.

However, if the function is called more than once, reading the i'th argument inside the function will result in the least upper bound of all supplied i'th arguments because we have no context sensivity! The following example illustrates this:

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def f(p1): 
	return p1
f(10)
x = f(20) # x becomes the top element of the integer lattice, not 20
	\end{minted}
\caption{An example illustrating the consequence of not having context sensivity.}
\end{listing}

Next, we update the call graph accordingly by inserting call edges from the call node to the entry node of $f$ and from the exit node of $f$ to the after call node. This implies that the worklist of our fixed point algorithm will be updated with the entry node of $f$, such that it will be reevaluated.

At the \inlinecode{FunctionEntryNode} we change the runtime scope chain to the static scope chain of the function, which can be found on the function object on the heap (see the $Object$ lattice).

When the fixed point algorithm have processed the function the after call node can read the return value of the function (which we store in a special constant register), and store it on the stack.

\section{Strong or weak updates of local variables}
Since onlu one scope object is created for each function, there is a big potential for presition loss because soundness would dictate that all writes to local variable are modeled as weak updates, i.e. least upper bound between current value and the new value. This is due to the fact that a scobe object of a perticular function might exist in more than one instance at runtime, as it is the case with recursive functions. An examble would be if, at runtime, one instance of a scope object for a particular function has some variable z to be 5 while another has it to be 10, then the analysis would need to emulate both these values at the same time in the scope object. Ths can be achieved by taking the least upper bound of the two values, but this has potential to grealt reduce the accuraru of the analysis since the only upperbound possible in our value lattice is the any integer element.

This problem only arises in the presence of recursive functions, so to enable the analysis to do strong updates a flag is introduced to tell the analysis if it can assume no recursive functions. This is a very fast to implement and allowed more time to focus on the magic methods, which on its own doesn't introduce any recursion.

Alternativly to this fix, the call graph could be inspected for lopps indicating recusive functions. However since the call graph is built dynamicly as a part of the analysis a recursive function might not appear as recursive at the current iteration possibly leading to strong updates, thus special care is needed when functions are labeled recursive.

A different approached could be to use the recency abstraction as introduced by \cite{recency}. This could work very well because all writes to local objects at runtime happen to the lastest instantiated stackframe, which is exactly the situation recency abstraction enables strong updates over weak updates.

\section{Further work with functions}
In Python it is possible to unfold e.g. a dictionary to the arguments of a function:

\begin{listing}[H]
	\begin{minted}[linenos]{python}
def foo(bar, baz):
	return bar + baz
params = { 'bar': 'bar', 'baz': 'baz' }
foo(*params) # 'barbaz'
	\end{minted}
\caption{Unfolding of a dictionary to the parameters a function.}\label{code:UnfoldDictFunctionExample}
\end{listing}

Currently, our analysis does not support this kind of parameter passing. Also, it does not support the special \inlinecode{**args} parameter that collects all of the superfluous arguments in a list, quite similar to the \inlinecode{arguments} object that is available inside functions in JavaScript.